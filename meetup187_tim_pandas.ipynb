{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwai21/Python-Baby-Steps/blob/master/meetup187_tim_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MeetUp 187 - Beginners' Python and Machine Learning - 26 Jul 2023 - pandas\n",
        "\n",
        "Learning objectives:\n",
        "- Introduction to data handling with pandas\n",
        "\n",
        "\n",
        "Links:\n",
        "- Colab: https://colab.research.google.com/drive/1FODx3cH8h3DOx6mRlzDgKrWk0rMZklfd\n",
        "- Youtube: https://youtu.be/r058lI5Yr8E\n",
        "- Meetup:  https://www.meetup.com/beginners-python-machine-learning/events/294698691/\n",
        "- Github:  https://github.com/timcu/bpaml-sessions/tree/master/online\n",
        "\n",
        "@author D Tim Cummings\n",
        "\n",
        "Today we are introducing pandas and some of its features useful for data science. We will collect data from an online API and store in a DataFrame. Then we will perform filtering, converting, calculating and pivoting the data.\n",
        "\n",
        "- https://pandas.pydata.org\n",
        "\n",
        "# Using Google Colab / Jupyter Notebooks / IPython\n",
        "\n",
        "- type into a cell\n",
        "- press `<shift><enter>` to execute the cell\n",
        "- cells can be python code or markdown text or input fields\n",
        "- use ? or Help menu for help\n",
        "- see Help menu > Keyboard shortcuts\n"
      ],
      "metadata": {
        "datalore": {
          "node_id": "FjlrUXpucaDRNOcjWc1zHY",
          "type": "MD",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "l_FACqeBwe_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to determine pandas version from the command line\n",
        "!pip list | grep pandas"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Og0W1362roqwK1KenMTmPk",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "4yF_TWlfwe_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start using pandas by importing it. To save time typing 'pd' instead of 'pandas' use an import alias\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3UFXXGO3TW2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get some data from https://www.data.brisbane.qld.gov.au/data/dataset/public-art and store it in a DataFrame\n",
        "# Use the pandas method read_csv to read data from URL or from a file\n",
        "# Good if you know the encoding. I had to try a few before this worked.\n",
        "# Default encoding is 'utf-8'. I also tried 'latin1' which didn't show quotes correctly\n",
        "url_art = 'https://www.data.brisbane.qld.gov.au/data/dataset/1e11bcdd-fab1-4ec5-b671-396fd1e6dd70/resource/3c972b8e-9340-4b6d-8c7b-2ed988aa3343/download/public-art-open-data-2023-03-14.csv'\n",
        "df_art = pd.read_csv(url_art, encoding='cp1252')\n",
        "# Look at the data\n",
        "df_art"
      ],
      "metadata": {
        "id": "4OVXqBfXScgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In pandas, DataFrames are a two dimensional array of data.\n",
        "# Series are a one dimensional array of data. Each column in a DataFrame can be used a Series\n",
        "# Use [] notation with name of column to isolate just one column\n",
        "s = df_art['Item_title']\n",
        "print(f\"df_art is a {type(df_art)} and s is a {type(s)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "2H9k0HA1yw7aqaTyM9Kwji",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "73z1wy-Mwe_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A series has an index as well as a column of values\n",
        "s"
      ],
      "metadata": {
        "id": "NoIlvkD0Y4fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a sub DataFrame use a list of column names\n",
        "df_art[['Item_title', 'Latitude', 'Longitude']]"
      ],
      "metadata": {
        "id": "8LuiTpNaY4cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Click on wizard to view dataframe in colab,\n",
        "# Click chart icon to show example charts\n",
        "# Select chart Longitude vs Latitude\n",
        "# Add cell\n",
        "# Edit supplied code to plot Latitude vs Longitude and change scatter_plot_size to 7.5"
      ],
      "metadata": {
        "id": "BdcNFBstGiPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify code to show just Latitude (y) versus Longitude (x) with scatter_plot_size=5"
      ],
      "metadata": {
        "id": "y-7IlxesGw8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_63NPxyH5Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "def scatter_plots(df, colname_pairs, scatter_plot_size=2.5, size=8, alpha=.6):\n",
        "  from matplotlib import pyplot as plt\n",
        "  plt.figure(figsize=(len(colname_pairs) * scatter_plot_size, scatter_plot_size))\n",
        "  for plot_i, (x_colname, y_colname) in enumerate(colname_pairs, start=1):\n",
        "    ax = plt.subplot(1, len(colname_pairs), plot_i)\n",
        "    ax.scatter(df[x_colname], df[y_colname], s=size, alpha=alpha)\n",
        "    plt.xlabel(x_colname)\n",
        "    plt.ylabel(y_colname)\n",
        "    ax.spines[['top', 'right',]].set_visible(False)\n",
        "    # Add some titles if they are provided\n",
        "    if \"Item_title\" in df:\n",
        "        for idx in df.index:\n",
        "            if idx % 5 == 0:\n",
        "                # We can refer to individual items in a DataFrame using .at[row, col]\n",
        "                x = df.at[idx, x_colname]\n",
        "                y = df.at[idx, y_colname]\n",
        "                t = df.at[idx, \"Item_title\"]\n",
        "                if y < -27.49 or y > -27.45:\n",
        "                    # show text next to some data points\n",
        "                    ax.text(x + 0.001, y + 0.001, t)\n",
        "  plt.tight_layout()\n",
        "  return plt\n",
        "\n",
        "chart = scatter_plots(df_art, *[[['Longitude', 'Latitude']]], scatter_plot_size=5, **{})\n",
        "chart;"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YyXCW3Z5GPEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using .at to access a single data element\n",
        "df_art.at[4, \"Item_title\"]"
      ],
      "metadata": {
        "id": "Xa9fGuLKVsXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Methods to access part of DataFrame via named index and columns\n",
        "# df.at[row, col] => access one element\n",
        "# df.loc[rows, cols] => access multiple elements\n",
        "\n",
        "# Methods to access part of DataFrame via numbered index and columns\n",
        "# df.iat[irow, icol] => access one element by zero based integer indexes\n",
        "# df.iloc[irows, icols] => access multiple elements by zero based integer indexes"
      ],
      "metadata": {
        "id": "6PXwPRiZYaxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using .loc to access a single data element\n",
        "df_art.loc[4, \"Item_title\"]"
      ],
      "metadata": {
        "id": "FQ5NLxufVsNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .loc can be used with a sub DataFrame of rows just like we retrieved a sub DataFrame of columns before\n",
        "# Notice how slice includes ending row which is unusual in Python\n",
        "df_art.loc[2:5]"
      ],
      "metadata": {
        "id": "NlJGOjrsZQLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also slice on columns, but have to provide a slice for rows. : = all rows\n",
        "# Notice how we have to provide a space at end of Material because that is in original data\n",
        "df_art.loc[:, 'Artist':'Material ']"
      ],
      "metadata": {
        "id": "Iv9vq513a1dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all column names\n",
        "df_art.columns"
      ],
      "metadata": {
        "id": "MRsW4CPca1Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can rename columns. Notice how we are using `inplace=True` so we are editing the DataFrame rather than returning a new one.\n",
        "new_names = {n: n.strip() for n in df_art.columns}\n",
        "print(f\"{new_names=}\")\n",
        "df_art.rename(columns=new_names, inplace=True)\n",
        "df_art.columns"
      ],
      "metadata": {
        "id": "0bYaNPT5dHjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save csv file from BCC Open Data to see what caused the spaces at end of column names\n",
        "from urllib.request import urlopen\n",
        "with urlopen(url_art) as file_obj:\n",
        "    with open('public_art.csv', 'wb') as pa_csv:\n",
        "        pa_csv.write(file_obj.read())\n",
        "# View the file using the operating system command line rather than python code\n",
        "!head public_art.csv"
      ],
      "metadata": {
        "id": "dS0xMXgHY4Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced - Find which lines are not utf-8\n",
        "with open('public_art.csv', 'rb') as pa_csv:\n",
        "    for i, line in enumerate(pa_csv):\n",
        "        try:\n",
        "            s = line.decode('utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            print(i, ' '*10, line)\n",
        "            # latin1 and iso-8859-1 are the same\n",
        "            # https://docs.python.org/3.9/library/codecs.html#standard-encodings\n",
        "            for encoding in ['cp1252', 'latin1', 'mac-roman']:\n",
        "                s = line.decode(encoding)\n",
        "                print(i, f\"{encoding:12}\", s.strip())"
      ],
      "metadata": {
        "id": "7fx_G80z3GY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_art"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "31WLE8yugK2rF1xvC3DHba",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "EniITUlswe_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can use a list of bools on rows or columns to specify which ones to include\n",
        "df_art.loc[:, [True, False, True, False, False, False, False, False]]"
      ],
      "metadata": {
        "id": "W3orsgjCegLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can create a list of bools using an expression\n",
        "df_art.columns.str.contains(\"_\")"
      ],
      "metadata": {
        "id": "krJdurKJegHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put them together\n",
        "df_art.loc[:, df_art.columns.str.contains(\"_\")]"
      ],
      "metadata": {
        "id": "_nlNT0GaegDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Could also use earlier expression df[[column names, ...]]\n",
        "df_art[df_art.columns[df_art.columns.str.contains(\"_\")]]"
      ],
      "metadata": {
        "id": "XJgnifzPpPN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More common to filter this way on rows\n",
        "# Find art installed last year\n",
        "df_art.loc[df_art['Installed']==2022]\n",
        "# Alternatively\n",
        "# df_art[df_art['Installed']==2022]\n"
      ],
      "metadata": {
        "id": "Dcjw_25OegAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at traffic data\n",
        "# https://www.data.brisbane.qld.gov.au/data/dataset/traffic-management-key-corridor-monthly-performance-report/resource/70da5292-87a1-4fd4-8a35-b0a723566884\n",
        "# Remove bom=True from CSV URL https://www.data.brisbane.qld.gov.au/data/datastore/dump/70da5292-87a1-4fd4-8a35-b0a723566884?bom=True\n",
        "url_tfc = 'https://www.data.brisbane.qld.gov.au/data/datastore/dump/70da5292-87a1-4fd4-8a35-b0a723566884'\n",
        "with urlopen(url_tfc) as file_obj:\n",
        "    with open('traffic.csv', 'wb') as tfc_csv:\n",
        "        tfc_csv.write(file_obj.read())\n",
        "# View the file using the operating system command line rather than python code\n",
        "!head traffic.csv"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "HJMUrMx1Svtm2qgAnkLorT",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "NFYdm_6HwfAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read csv from file\n",
        "df_tfc = pd.read_csv('traffic.csv')\n",
        "df_tfc"
      ],
      "metadata": {
        "id": "IfEgS1BHqbsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform arithmetical operation on a column and store the result\n",
        "df_tfc['Volume per hour average'] = df_tfc['Average Weekday Daily Traffic (Veh/day)'] / 24\n",
        "df_tfc"
      ],
      "metadata": {
        "id": "EIIMxK3vr4uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculations can be more complicated, although not every calculation can work\n",
        "# Operators (+,-,*,/) are overriden so this works.\n",
        "vol_am = 'Volume per hour AM Peak'\n",
        "vol_pm = 'Volume per hour PM Peak'\n",
        "tt_am = 'Average TT AM Peak (seconds)'\n",
        "tt_pm = 'Average TT PM Peak (seconds)'\n",
        "tt = 'Average TT Peak (seconds)'\n",
        "df_tfc[tt] = (df_tfc[tt_am] * df_tfc[vol_am] + df_tfc[tt_pm] * df_tfc[vol_pm]) / (df_tfc[vol_am] + df_tfc[vol_pm])\n",
        "df_tfc"
      ],
      "metadata": {
        "id": "euzIJQE5QPBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfc[df_tfc['Month']=='May']"
      ],
      "metadata": {
        "id": "DJlLy5et8BhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data for Site ID 2 in May 2023\n",
        "avg_tt = (1865 * 1182 + 1899 * 1023) / (1865 + 1899)\n",
        "avg_tt"
      ],
      "metadata": {
        "id": "CENPqIITQUOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check using assert and filters\n",
        "assert avg_tt == df_tfc.loc[(df_tfc['Year'] == 2023) & (df_tfc['Month'] == 'May') & (df_tfc['Site ID'] == 2), 'Average TT Peak (seconds)'].values[0]\n",
        "df_tfc.loc[(df_tfc['Year'] == 2023) & (df_tfc['Month'] == 'May') & (df_tfc['Site ID'] == 2), 'Average TT Peak (seconds)']"
      ],
      "metadata": {
        "id": "q_43ndVjbzcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check using query instead of filters\n",
        "assert avg_tt == df_tfc.query('Year == 2023 & Month == \"May\" & `Site ID` == 2')['Average TT Peak (seconds)'].values[0]\n",
        "df_tfc.query('Year == 2023 & Month == \"May\" & `Site ID` == 2')['Average TT Peak (seconds)']"
      ],
      "metadata": {
        "id": "qf4mFgAocCDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To call functions use numpy functions rather than Python functions\n",
        "import math\n",
        "# The following won't work\n",
        "# df_tfc['sin_id'] = math.sin(df_tfc['_id'] * math.pi / 180)"
      ],
      "metadata": {
        "id": "TFU3vzk5Rx6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use sin from numpy which can work on ndarrays\n",
        "import numpy as np\n",
        "df_tfc['sin_id'] = np.sin(df_tfc['_id'] * math.pi / 180)\n",
        "df_tfc"
      ],
      "metadata": {
        "id": "-qwQ7EykTHoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For datetime use pandas.to_datetime\n",
        "df_tfc['Year Month'] = pd.to_datetime(df_tfc['Year'].astype(str) + df_tfc['Month'], format=(\"%Y%b\"))\n",
        "df_tfc"
      ],
      "metadata": {
        "id": "G6UJ3Rv6T3Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the Site names more interesting than Site ID and take a portion of the DataFrame\n",
        "df_tfc['Site Name'] = 'Site ' + df_tfc['Site ID'].astype(str).str.zfill(2)\n",
        "df_vol = df_tfc[['Site Name', 'Year Month', 'Average Weekday Daily Traffic (Veh/day)']]\n",
        "df_vol.head(30)"
      ],
      "metadata": {
        "id": "Ul6-tz-4TSF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can pivot data\n",
        "df_pivot = df_vol.pivot(index='Year Month', columns='Site Name', values='Average Weekday Daily Traffic (Veh/day)')\n",
        "df_pivot"
      ],
      "metadata": {
        "id": "ruKXtDrxTT7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2IuLMfQZ2rF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "datalore": {
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "base_environment": "default",
      "packages": [],
      "report_row_ids": [],
      "version": 3
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}